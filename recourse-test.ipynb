{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test for using actionable-recourse, provided on https://github.com/ustunb/actionable-recourse\n",
    "\n",
    "In order to compare recourse for several similar classifiers, we use cross validation to fit several logistic regression models (Is this the right way?). In the next step, we want to check whether the flipsets generated for one of them apply also for the other classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold as CVGenerator\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import recourse as rs\n",
    "from recourse.builder import ActionSet #FIX\n",
    "from recourse.flipset import Flipset #FIX\n",
    "from recourse.auditor import RecourseAuditor #FIX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/ustunb/actionable-recourse/master/examples/paper/data/credit_processed.csv'\n",
    "df = pd.read_csv(url, skipinitialspace=True)\n",
    "n_data = len(df) # 30.000\n",
    "cut_factor = 0.1 # 1 -> full dataset considered (but randomly shuffled)\n",
    "idxs = np.random.choice(n_data, int((1-cut_factor)*n_data), replace = False)\n",
    "# randomly choose cut_factor * n samples to fasten analysis\n",
    "df = df.drop(idxs)\n",
    "y, X = df.iloc[:, 0], df.iloc[:, 1:]\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEW: Use Cross validation to train several different classifiers (takes some time!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "alter_C = True\n",
    "n_splits = 20\n",
    "if not alter_C:\n",
    "    clf = LogisticRegression(max_iter=10000)\n",
    "    cv = cross_validate(clf, X, y, cv=n_splits, return_estimator=True)\n",
    "    cv_scores = cv['test_score']\n",
    "    classifiers = np.array(cv['estimator'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative: Use GridSearchCV on parameter C (takes some time!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  1.1min finished\n"
     ]
    }
   ],
   "source": [
    "if alter_C:\n",
    "    cv_generator = CVGenerator(n_splits = 10)\n",
    "    clf = LogisticRegression(max_iter=10000, solver='lbfgs')\n",
    "\n",
    "    # this code is for general purpose train/test evaluation using GridSearchCV\n",
    "    gridsearch = GridSearchCV(\n",
    "        clf, \n",
    "        param_grid={'C':np.logspace(-4, 3, num=n_splits)},\n",
    "        scoring='accuracy',\n",
    "        cv=cv_generator,\n",
    "        verbose=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    gridsearch.fit(X,y)\n",
    "    grid_search_df = pd.DataFrame(gridsearch.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43e772e3639f40e69829e1710bf69b7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if alter_C:\n",
    "    # cache a model for each parameter combination, trained on all data\n",
    "    classifiers = []\n",
    "    classifier_Cs = []\n",
    "    for idx, p in tqdm(list(grid_search_df.params.iteritems())):\n",
    "        model = copy.deepcopy(clf.set_params(**p)).fit(X,y)\n",
    "        classifiers.append(model)\n",
    "        classifier_Cs.append(p.items())\n",
    "    cv_scores = grid_search_df['mean_test_score']\n",
    "    classifiers = np.array(classifiers)\n",
    "    # Is it inconsistent to consider score before fitting the whole train set? \n",
    "    # But otherwise, it would violate train-test splitting\n",
    "    # CV + fit is a bit of an overkill here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEW: Select those classifiers that achieve performance within certain tolerance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8006666666666666\n",
      "0.005204024533476895\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "#X_test = X[:3]\n",
    "#for i, est in enumerate(scores['estimator']):\n",
    "#    print(scores['test_score'][i], est.predict(X_test))\n",
    "tolerance = 1*np.std(cv_scores)\n",
    "good_classifiers = classifiers[cv_scores >= np.max(cv_scores) - tolerance]\n",
    "\n",
    "print(np.max(cv_scores))\n",
    "print(cv_scores.std())\n",
    "print(len(good_classifiers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = [clf.predict(X) for clf in good_classifiers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "customize the set of actions and align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_sets=[]\n",
    "for clf in good_classifiers:\n",
    "    ## matrix of features. ActionSet will learn default bounds and step-size.\n",
    "    A = ActionSet(X)\n",
    "    ## specify immutable variables\n",
    "    A['Married'].mutable = False \n",
    "    ## can only specify properties for multiple variables using a list\n",
    "    A[['Age_lt_25', 'Age_in_25_to_40', 'Age_in_40_to_59', 'Age_geq_60']].mutable = False \n",
    "    A['EducationLevel'].step_direction = 1  ## force conditional immutability.\n",
    "    A['EducationLevel'].step_size = 1  ## set step-size to a custom value.\n",
    "    A['EducationLevel'].step_type = \"absolute\"  ## force conditional immutability.\n",
    "    A['EducationLevel'].bounds = (0, 3)\n",
    "    A['TotalMonthsOverdue'].step_size = 1  ## set step-size to a custom value.\n",
    "    A['TotalMonthsOverdue'].step_type = \"absolute\"  ## discretize on absolute values of feature rather than percentile values\n",
    "    A['TotalMonthsOverdue'].bounds = (0, 100)  ## set bounds to a custom value.\n",
    "    \n",
    "    ## tells `ActionSet` which directions each feature should move in to produce positive change.\n",
    "    A.align(clf)\n",
    "    action_sets.append(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEW: change inputs according to flipsets (takes some time!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "j_clf = 0 # flipset generated for j_th classifier TODO later: iterate j_clf?\n",
    "k_fs = 0  # k-th flipset is applied; MAYDO later: iterate k_fs?\n",
    "        # when iterating j_clf, we would probably not filter X here...\n",
    "xs = copy.deepcopy(X.iloc[np.flatnonzero(yhat[j_clf] <= 0)]).to_numpy()\n",
    "for i in range(len(xs)):\n",
    "    fs = Flipset(x = xs[i], action_set = action_sets[j_clf], clf = good_classifiers[j_clf])\n",
    "    fs.populate(enumeration_type = 'distinct_subsets', total_items = 10)\n",
    "    for j, fi in enumerate(fs._df['feature_idx'][k_fs]):\n",
    "        xs[i,fi] = fs._df['x_new'][k_fs][j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEW: Measure for how many individuals the adjusted input leads to desirable outcomes for each classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 0.16080402010050251,\n",
       " 0.09045226130653267,\n",
       " 0.08040201005025126,\n",
       " 0.17587939698492464,\n",
       " 0.20100502512562815,\n",
       " 0.23618090452261306,\n",
       " 0.20603015075376885,\n",
       " 0.2914572864321608,\n",
       " 0.20603015075376885,\n",
       " 0.271356783919598,\n",
       " 0.2663316582914573,\n",
       " 0.2562814070351759,\n",
       " 0.271356783919598,\n",
       " 0.2964824120603015]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flips = []\n",
    "preds = []\n",
    "for clf in good_classifiers:\n",
    "    ys = clf.predict(xs)\n",
    "    preds.append(ys)\n",
    "    flips.append(np.mean(ys))\n",
    "flips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** Use only negatively predicted datapoints; Make whole thing more sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "X_new = np.array([copy.deepcopy(X).to_numpy() for clf in good_classifiers])\n",
    "# X_new[clf that generated flipset; datapoint; feature]\n",
    "k_fs = 0 # k-th flipset is applied; MAYDO later: iterate k_fs?\n",
    "for j_clf, clf in enumerate(good_classifiers):\n",
    "    print(\"Apply flipsets of classifier\", j_clf)\n",
    "    for i in range(X_new.shape[1]):\n",
    "        fs = Flipset(x = X_new[j_clf, i, :], action_set = action_sets[j_clf], clf = clf)\n",
    "        fs.populate(enumeration_type = 'distinct_subsets', total_items = 10)\n",
    "        X_new[j_clf, i, fs._df['feature_idx'][k_fs]] = fs._df['x_new'][k_fs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    1    0    1    0    0    3 1880   90    0    0    0 1730   90\n",
      "     1    9    1]\n",
      " [   0    1    1    0    0    0    3  678   60    0    0    4  470   42\n",
      "     1    8    1]\n",
      " [   1    0    0    0    1    0    2 5990  430    0    0    0 5370  240\n",
      "     1   10    1]\n",
      " [   0    1    0    0    1    0    2 1590   40    0    3    3 1590 1722\n",
      "     1   15    1]\n",
      " [   0    1    0    1    0    0    2 1880  610    0    0    6 1260    0\n",
      "     1    7    1]]\n",
      "----\n",
      "[[   0    1    0    1    0    0    3 1880   90    0    0    0 1730   90\n",
      "     1    9    1]\n",
      " [   0    1    1    0    0    0    3  678   60    0    0    4  470   42\n",
      "     1    8    1]\n",
      " [   1    0    0    0    1    0    2 5990  430    0    0    0 5370  240\n",
      "     1   10    1]\n",
      " [   0    1    0    0    1    0    2 1590   40    0    3    3 1590 1722\n",
      "     1   15    1]\n",
      " [   0    1    0    1    0    0    2 1880  610    0    0    6 1260    0\n",
      "     1    7    1]]\n",
      "----\n",
      "[[   0    1    0    1    0    0    3 1880   90    0    0    0 1730   90\n",
      "     1   12    1]\n",
      " [   0    1    1    0    0    0    3  540   60    0    0    4  470   40\n",
      "     1   10    1]\n",
      " [   1    0    0    0    1    0    2 5990  430    0    0    0 5370  240\n",
      "     1   13    1]\n",
      " [   0    1    0    0    1    0    2 1590   40    0    3    3 1590   10\n",
      "     1   15    1]\n",
      " [   0    1    0    1    0    0    2 1880  610    0    0    6 1260    0\n",
      "     1    8    1]]\n",
      "----\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "----\n",
      "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(xs[10:15,:])\n",
    "print(\"----\")\n",
    "print(X_new[0, yhat[0]<=0,:][10:15,:])\n",
    "print(\"----\")\n",
    "print(X.to_numpy()[yhat[0]<=0,:][10:15,:])\n",
    "print(\"----\")\n",
    "print(preds[0][10:20])\n",
    "print(\"----\")\n",
    "print(yhat_new[0, 0, yhat[0]<=0][10:20])\n",
    "# when applying flipsets, data is only changed for the first 12 datapoints (at least for classifier 0 generating the flipsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 15, 3000)\n"
     ]
    }
   ],
   "source": [
    "yhat_new = np.array([[clf.predict(X_new[j]) for j in range(len(good_classifiers))] for clf in good_classifiers])\n",
    "print(yhat_new.shape)\n",
    "# yhat_new[clf that predicted outcome; clf that generated flipset; datapoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 17)\n",
      "(15, 3000)\n",
      "(15, 3000, 17)\n",
      "(15, 15, 3000)\n",
      "[[0.05882353 0.05882353 0.05882353 ... 0.05882353 0.05882353 0.05882353]\n",
      " [0.05882353 0.05882353 0.05882353 ... 0.05882353 0.05882353 0.05882353]\n",
      " [0.05882353 0.05882353 0.05882353 ... 0.05882353 0.05882353 0.05882353]\n",
      " ...\n",
      " [0.05882353 0.05882353 0.05882353 ... 0.05882353 0.05882353 0.05882353]\n",
      " [0.05882353 0.11764706 0.05882353 ... 0.05882353 0.05882353 0.05882353]\n",
      " [0.05882353 0.05882353 0.05882353 ... 0.05882353 0.11764706 0.05882353]]\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(np.asarray(yhat).shape)\n",
    "print(X_new.shape)\n",
    "print(yhat_new.shape)\n",
    "changed = np.asarray(X) != np.asarray(X_new)\n",
    "print(changed.mean(axis = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(199, 15)\n",
      "[1.         1.         1.         1.         0.93467337 0.88442211\n",
      " 0.74874372 0.78894472 0.67839196 0.75376884 0.70351759 0.73869347\n",
      " 0.74371859 0.72864322 0.72864322]\n",
      "1.0\n",
      "(221, 15)\n",
      "[0.14932127 1.         0.99547511 0.8959276  0.77828054 0.74208145\n",
      " 0.66515837 0.70588235 0.63348416 0.72850679 0.65158371 0.68325792\n",
      " 0.68325792 0.67420814 0.6561086 ]\n",
      "0.3333333333333333\n",
      "(240, 15)\n",
      "[0.075      0.32083333 1.         0.85833333 0.73333333 0.72083333\n",
      " 0.6        0.62916667 0.5875     0.64583333 0.60833333 0.60416667\n",
      " 0.60833333 0.6        0.59166667]\n",
      "0.3333333333333333\n",
      "(256, 15)\n",
      "[0.0625     0.234375   0.57421875 1.         0.71875    0.71875\n",
      " 0.59765625 0.62890625 0.60546875 0.66015625 0.609375   0.625\n",
      " 0.62890625 0.625      0.57421875]\n",
      "0.8\n",
      "(279, 15)\n",
      "[0.12544803 0.25448029 0.46236559 0.64157706 1.         0.7921147\n",
      " 0.6702509  0.68100358 0.65232975 0.72759857 0.68458781 0.66308244\n",
      " 0.67383513 0.67383513 0.61290323]\n",
      "0.7333333333333333\n",
      "(284, 15)\n",
      "[0.1443662  0.22535211 0.3943662  0.53873239 0.65140845 1.\n",
      " 0.66549296 0.69014085 0.66197183 0.73591549 0.69366197 0.68661972\n",
      " 0.6971831  0.6971831  0.61619718]\n",
      "0.6666666666666666\n",
      "(298, 15)\n",
      "[0.15100671 0.28187919 0.34899329 0.42281879 0.49328859 0.51006711\n",
      " 1.         0.75838926 0.74832215 0.7114094  0.72818792 0.73825503\n",
      " 0.74832215 0.76845638 0.61409396]\n",
      "0.6666666666666666\n",
      "(316, 15)\n",
      "[0.13291139 0.25949367 0.34810127 0.40822785 0.44303797 0.47151899\n",
      " 0.53164557 1.         0.64873418 0.68670886 0.67721519 0.76265823\n",
      " 0.76898734 0.75316456 0.65189873]\n",
      "0.8\n",
      "(313, 15)\n",
      "[0.16613419 0.26198083 0.2971246  0.36102236 0.38658147 0.4313099\n",
      " 0.485623   0.60063898 1.         0.65495208 0.77316294 0.80191693\n",
      " 0.84345048 0.86261981 0.52076677]\n",
      "0.9333333333333333\n",
      "(320, 15)\n",
      "[0.13125  0.26875  0.321875 0.3875   0.421875 0.453125 0.496875 0.646875\n",
      " 0.64375  1.       0.728125 0.753125 0.759375 0.721875 0.559375]\n",
      "0.6\n",
      "(316, 15)\n",
      "[0.15189873 0.25316456 0.30696203 0.36708861 0.37974684 0.41455696\n",
      " 0.43987342 0.5664557  0.62658228 0.63924051 1.         0.71835443\n",
      " 0.73734177 0.7056962  0.4556962 ]\n",
      "0.26666666666666666\n",
      "(323, 15)\n",
      "[0.15479876 0.28173375 0.3003096  0.35913313 0.37770898 0.40557276\n",
      " 0.43653251 0.54489164 0.61919505 0.57894737 0.65325077 1.\n",
      " 0.94736842 0.75232198 0.40247678]\n",
      "0.8666666666666667\n",
      "(322, 15)\n",
      "[0.14596273 0.27329193 0.30124224 0.36024845 0.3757764  0.40372671\n",
      " 0.43167702 0.54347826 0.57763975 0.55279503 0.63975155 0.76086957\n",
      " 1.         0.73602484 0.39440994]\n",
      "0.3333333333333333\n",
      "(317, 15)\n",
      "[0.15141956 0.2681388  0.29968454 0.35962145 0.38170347 0.40694006\n",
      " 0.44164038 0.59621451 0.66246057 0.59936909 0.72239748 0.82649842\n",
      " 0.85804416 1.         0.4384858 ]\n",
      "0.6666666666666666\n",
      "(305, 15)\n",
      "[0.1704918  0.30491803 0.34098361 0.41639344 0.45901639 0.50491803\n",
      " 0.55081967 0.76721311 0.78688525 0.82622951 0.81639344 0.97377049\n",
      " 0.97704918 0.9442623  1.        ]\n",
      "0.26666666666666666\n"
     ]
    }
   ],
   "source": [
    "for j_clf, clf in enumerate(good_classifiers):\n",
    "    yhat_unpleased = yhat_new[j_clf,:,yhat[j_clf] == 0]\n",
    "    print(yhat_unpleased.shape) #[datapoint; clf that predicted outcome] why switched?\n",
    "    flip_accuracy = yhat_unpleased.mean(axis = 0)\n",
    "    print(flip_accuracy)\n",
    "    # only the first 17 datapoints are affected WTF -> dimensions have to be messed up somewhere!!...\n",
    "    print(yhat_unpleased[j_clf].mean())\n",
    "#flip_accuracy = yhat_new[j_measure, j_generate, np.flatnonzero(yhat[j_generate] == 0)].mean()\n",
    "#flip_accuracy = yhat_new[:,:,yhat[0] == 0].mean(axis = 2)\n",
    "#print(flip_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Married                                    0\n",
      "Single                                     1\n",
      "Age_lt_25                                  1\n",
      "Age_in_25_to_40                            0\n",
      "Age_in_40_to_59                            0\n",
      "Age_geq_60                                 0\n",
      "EducationLevel                             3\n",
      "MaxBillAmountOverLast6Months             580\n",
      "MaxPaymentAmountOverLast6Months          100\n",
      "MonthsWithZeroBalanceOverLast6Months       0\n",
      "MonthsWithLowSpendingOverLast6Months       0\n",
      "MonthsWithHighSpendingOverLast6Months      5\n",
      "MostRecentBillAmount                     470\n",
      "MostRecentPaymentAmount                  100\n",
      "TotalOverdueCounts                         1\n",
      "TotalMonthsOverdue                         8\n",
      "HistoryOfOverduePayments                   1\n",
      "Name: 16, dtype: int64\n",
      "[  0   1   1   0   0   0   3 580 100   0   0   5 470 105   1   8   1]\n",
      "[1. 1. 0. 1. 1. 1. 0. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(X.iloc[2])\n",
    "print(X_new[0,2])\n",
    "print(yhat[0][:10])\n",
    "print(yhat_new[0,0,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    1    1    0    0    0    3  580  100    0    0    5  470  105\n",
      "     1    8    1]\n",
      " [   0    1    0    1    0    0    2 1940  150    0    6    0 1780   80\n",
      "     1    9    1]\n",
      " [   1    0    0    0    1    0    2   80   30    0    6    0   50   42\n",
      "     1    9    1]\n",
      " [   0    1    0    1    0    0    3 5190  350    0    0    6 4900  230\n",
      "     1    9    1]\n",
      " [   0    1    0    1    0    0    3  770   80    0    0    0  690    0\n",
      "     1    8    1]\n",
      " [   0    1    0    1    1    0    2 5190  460    0    0    5 4450  460\n",
      "     1   10    1]\n",
      " [   0    1    0    1    0    0    3 1550   60    0    0    6 1440   60\n",
      "     1    7    1]\n",
      " [   0    1    0    1    0    0    2 5790  380    0    0    3 5790  270\n",
      "     1   10    1]\n",
      " [   1    0    0    1    0    0    1 2910  150    0    0    0 2750  168\n",
      "     1   10    1]\n",
      " [   1    0    0    1    0    0    1 4430  330    0    0    6 4160  200\n",
      "     1    9    1]]\n",
      "after [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "befor [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "after [0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]\n",
      "befor [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "after [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "befor [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "after [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "befor [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "after [0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      "befor [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "after [0. 0. 0. 0. 1. 0. 0. 0. 1. 0.]\n",
      "befor [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "after [0. 1. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
      "befor [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "after [0. 1. 0. 0. 1. 1. 0. 0. 0. 0.]\n",
      "befor [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "after [0. 1. 0. 0. 1. 1. 0. 1. 1. 0.]\n",
      "befor [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "after [0. 0. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "befor [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "after [0. 1. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "befor [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "after [0. 1. 0. 0. 1. 1. 0. 1. 1. 0.]\n",
      "befor [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "after [0. 1. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "befor [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "after [0. 1. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "befor [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "after [0. 1. 0. 0. 1. 1. 0. 1. 1. 0.]\n",
      "befor [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(xs[:10])\n",
    "for j_clf in range(len(good_classifiers)):\n",
    "    print(\"after\", preds[j_clf][:10])\n",
    "    print(\"befor\", yhat[j_clf][np.flatnonzero(yhat[0] <= 0)][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Recourse Audit for each classifier on Training Data (Takes some time!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52c0c3eb59be4bd1aa3f393fd9363ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=199.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fee9b06014274fe2b987e08b5b0000d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=221.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f3946a55e2241b588ecc44471546414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=240.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16a84171c9124329a0cb8d6db3492998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=256.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "755357db9dc9402bb9aec9135db34051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=279.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ee8e0ce43f0450aadcaf4412d448e54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=284.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e00dc1e0439e459da517640c5709cb61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=298.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7050995bd0064e199d06727221d52726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=316.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb86b854843245f6908b762e1fbc0f9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=313.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64dd228c01244e6581dc5a84458067d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=320.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be5e322efae4e59a15091d9ec83775f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=316.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2c1ea30743148909fcf1dd1039a6144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=323.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72c41238ecc54dff93948db0fdede893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=322.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c39a919c5f24ea180166d3d4b0c8244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=317.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d83ea4f7e9b4091a1f2f283021e8c95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=305.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cost': [0.04378643277938842,\n",
       "  0.048634724098296535,\n",
       "  0.053305009106026625,\n",
       "  0.05550058975401354,\n",
       "  0.05345617409985927,\n",
       "  0.05561050869289419,\n",
       "  0.055975008326301985,\n",
       "  0.056043761182863215,\n",
       "  0.05742682141530978,\n",
       "  0.0566258921611109,\n",
       "  0.05879636740191718,\n",
       "  0.05762381107305099,\n",
       "  0.058091545384215626,\n",
       "  0.05818023972797271,\n",
       "  0.056392277783136664],\n",
       " 'feasible': [1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audit = {\"cost\": [], \"feasible\": []}\n",
    "for j, clf in enumerate(good_classifiers):\n",
    "    auditor = RecourseAuditor(action_sets[j], coefficients = clf.coef_[0], intercept = clf.intercept_[0])\n",
    "    audit_df = auditor.audit(X)  ## matrix of features over which we will perform the audit.\n",
    "    audit[\"feasible\"].append(audit_df['feasible'].mean())\n",
    "    audit[\"cost\"].append(audit_df['cost'].mean())\n",
    "audit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
